{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.0 One run full walktrhough \n",
    "1. Do the full walk through on the large data set\n",
    "2. Refactor the source code and bring it to individual scripts\n",
    "3. Ensure a full run with one click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#Set a base path in such way that full execuation will be possible with one click\n",
    "if os.path.split(os.getcwd())[-1]=='notebooks':\n",
    "    os.chdir('C:/Users/dhame/ds_covid-19/')\n",
    "\n",
    "'Your base path for this project is: '+os.path.split(os.getcwd())[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Update all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load src/data/get_rawdata_from_github.py\n",
    "#import require packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "#define a function to gather data from johns hopkins by doing git_pull\n",
    "def get_johns_hopkins_data():\n",
    "    git_pull = subprocess.Popen('git pull',\n",
    "                         cwd = os.path.dirname('data/raw/COVID-19/'),\n",
    "                         shell = True,stdout = subprocess.PIPE,stderr = subprocess.PIPE )\n",
    "    (out, error) = git_pull.communicate()\n",
    "    print(\"Error : \" + str(error))\n",
    "    print(\"out : \" + str(out))\n",
    "\n",
    "# define a function to gather data of only germany from RKI website: Just an an example, this data will be not used in the project\n",
    "def get_germany_data():\n",
    "    data_germany=requests.get('https://services7.arcgis.com/mOBPykOjAyBO2ZKk/arcgis/rest/services/RKI_Landkreisdaten/FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json')\n",
    "\n",
    "    json_object=json.loads(data_germany.content)\n",
    "    final_list=[]\n",
    "    for pos,each_dict in enumerate (json_object['features'][:]):\n",
    "        final_list.append(each_dict['attributes'])\n",
    "    pd_final_list=pd.DataFrame(final_list)\n",
    "    pd_final_list.to_csv('data/raw/NPGEO/Germany_statewise_data.csv',sep=';')\n",
    "    print(' Number of rows data stored (regionwise): '+str(pd_final_list.shape[0]))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    get_johns_hopkins_data()\n",
    "    get_germany_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 Transform jhon hopkins dataset into relational dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load src\\data\\preprocess_on_JH_data.py\n",
    "#importing required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# define function for store relational dataframe of Johns Hopkins data\n",
    "def store_relational_datafrmae_for_JH_data():\n",
    "    data_path='data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "    pd_raw=pd.read_csv(data_path)\n",
    "    pd_data=pd_raw.rename(columns={'Country/Region':'country','Province/State':'state'})\n",
    "    pd_data['state']=pd_data['state'].fillna('no')\n",
    "    pd_data=pd_data.drop(['Lat','Long'],axis=1)\n",
    "    Final_relational_model=pd_data.set_index(['state','country']) .T.stack(level=[0,1]).reset_index().rename(columns={'level_0':'date', 0:'confirmed'})\n",
    "\n",
    "    Final_relational_model['date']=Final_relational_model.date.astype('datetime64[ns]')\n",
    "    Final_relational_model.to_csv('data/processed/COVID_relational_confirmed.csv',sep=';',index=False)\n",
    "    print(' Total number of stored rows are: '+str(Final_relational_model.shape[0]))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    store_relational_datafrmae_for_JH_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3 Calculation of Filter and Doubling Rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load src\\features\\build_features_for_fitler_&_doubling_rate.py\n",
    "#importing required packageas\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression(fit_intercept=True)\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "\n",
    "# define helper function to calculate doubling rate via regression\n",
    "def calculate_doubling_time_via_regression(in_array):\n",
    "    y = np.array(in_array)\n",
    "    X = np.arange(-1,2).reshape(-1, 1)\n",
    "    assert len(in_array)==3\n",
    "    reg.fit(X,y)\n",
    "    intercept=reg.intercept_\n",
    "    slope=reg.coef_\n",
    "    return intercept/slope\n",
    "\n",
    "# define helper function to calculate savgol_filter\n",
    "def savgol_filter(df_input,column='confirmed',window=5):\n",
    "    degree=1\n",
    "    df_result=df_input\n",
    "    # fillup empty raw with 0 value in dataframe\n",
    "    filter_in=df_input[column].fillna(0)\n",
    "    # window size is used for filtering\n",
    "    result=signal.savgol_filter(np.array(filter_in),window,1)\n",
    "    df_result[str(column+'_filtered')]=result\n",
    "    return df_result\n",
    "\n",
    "def rolling_reg_func(df_input,col='confirmed'):\n",
    "    days_back=3\n",
    "    result=df_input[col].rolling(window=days_back,min_periods=days_back)\\\n",
    "                        .apply(calculate_doubling_time_via_regression,raw=False)\n",
    "    return result\n",
    "\n",
    "# define helper function to get merged DataFrame\n",
    "def calc_filtered_data(df_input,filter_on='confirmed'):\n",
    "    must_contain=set(['state','country',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Erro in calc_filtered_data not all columns in data frame'\n",
    "    # Make a copy of df_input here otherwise it will be overwritten\n",
    "    df_output=df_input.copy()\n",
    "\n",
    "    df_filtered_result=df_output[['state','country',filter_on]].groupby(['state','country']).apply(savgol_filter)#.reset_index()\n",
    "    df_output=pd.merge(df_output,df_filtered_result[[str(filter_on+'_filtered')]],left_index=True,right_index=True,how='left')\n",
    "    return df_output.copy()\n",
    "\n",
    "# define a function for calculation of doubling rate\n",
    "def calc_doubling_rate(df_input,filter_on='confirmed'):\n",
    "\n",
    "    must_contain=set(['state','country',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Error in calc_filtered_data not all columns in data frame'\n",
    "    df_doubling_rate= df_input.groupby(['state','country']).apply(rolling_reg_func,filter_on).reset_index()\n",
    "    df_doubling_rate=df_doubling_rate.rename(columns={filter_on:filter_on+'_DR',\n",
    "                             'level_2':'index'})\n",
    "    # Performing merging on the index of big table and on the index column after groupby operation\n",
    "    df_output=pd.merge(df_input,df_doubling_rate[['index',str(filter_on+'_DR')]],left_index=True,right_on=['index'],how='left')\n",
    "    df_output=df_output.drop(columns=['index'])\n",
    "    return df_output\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_data_reg=np.array([2,4,6])\n",
    "    result=calculate_doubling_time_via_regression(test_data_reg)\n",
    "    print('The slope of regression plot is: '+str(result))\n",
    "\n",
    "    df_JH_data=pd.read_csv('data/processed/COVID_relational_confirmed.csv',sep=';',parse_dates=[0])\n",
    "    df_JH_data=df_JH_data.sort_values('date',ascending=True).copy()\n",
    "\n",
    "    df_result_large=calc_filtered_data(df_JH_data)\n",
    "    df_result_large=calc_doubling_rate(df_result_large)\n",
    "    df_result_large=calc_doubling_rate(df_result_large,'confirmed_filtered')\n",
    "\n",
    "    mask_threshold=df_result_large['confirmed']>100\n",
    "    df_result_large['confirmed_filtered_DR']=df_result_large['confirmed_filtered_DR'].where(mask_threshold, other=np.NaN)\n",
    "    df_result_large.to_csv('data/processed/COVID_final_set.csv',sep=';',index=False)\n",
    "    print('This is it, Mate!!! --Calculation is done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4 Visual Board_1\n",
    "* Visual board_1 shows the plots for one or mulitple countries after selection. In addition, you have to select the option  among timeline confirmed, timeline confirmed filtered, timeline doubling rate and timeline doubling rate filtered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load src\\visualization\\Dashboard_1.py\n",
    "#importing required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output,State\n",
    "import plotly.graph_objects as go\n",
    "print('Your current dash board version is:' + dash.__version__)\n",
    "\n",
    "# import local CSV file as a dataframe\n",
    "df_input_large=pd.read_csv('data/processed/COVID_final_set.csv',sep=';')\n",
    "\n",
    "# for plotting\n",
    "fig = go.Figure()\n",
    "# for dashboard development\n",
    "app = dash.Dash()\n",
    "app.layout = html.Div([\n",
    "\n",
    "    dcc.Markdown('''\n",
    "    #  Data Science Project @ TU_KL on COVID-19 Dataset-Part 1\n",
    "\n",
    "    * Goal of the project is to learn data science by applying a cross-industry standard process. The default layout\n",
    "    contains the confirmed infected cases in the log-scale format for options (1 & 2); Approximated doubling rate\n",
    "    over 3 days for options (3 & 4) on the Y-axis and Timeline in Days on the X-axis.\n",
    "\n",
    "    ### The first dropdown menu enables selection of one or multiple  countries for visualization. The seconds dropdown menu contains four options:\n",
    "        1. The ‘Timeline Confirmed’ represents confirmed infected cases along the timeline.\n",
    "        2. The ‘Timeline Confirmed Filtered’ represents filtered (after applying sav-gol filter) confirmed infected cases along the timeline.\n",
    "        3. The ‘Timeline Doubling Rate’ represents calculated doubling rate on the infected cases along the timeline from the 1st option.\n",
    "        4. The ‘Timeline Doubling Rate Filtered’ represents calculated doubling rate on the infected cases along the timeline from the 2nd option.\n",
    "\n",
    "    '''),\n",
    "\n",
    "    dcc.Markdown('''\n",
    "    ## Select the Country for visualization\n",
    "    '''),\n",
    "\n",
    "    dcc.Dropdown(\n",
    "        id='country_drop_down',\n",
    "        options=[ {'label': each,'value':each} for each in df_input_large['country'].unique()],\n",
    "        value=['Germany','Italy'], # which are pre-selected in default layout\n",
    "        multi=True\n",
    "    ),\n",
    "\n",
    "    dcc.Markdown('''\n",
    "        ## Select Timeline of confirmed COVID-19 cases or the approximated doubling time\n",
    "        '''),\n",
    "\n",
    "\n",
    "    dcc.Dropdown(\n",
    "    id='doubling_time',\n",
    "    options=[\n",
    "        {'label': 'Timeline Confirmed ', 'value': 'confirmed'},\n",
    "        {'label': 'Timeline Confirmed Filtered', 'value': 'confirmed_filtered'},\n",
    "        {'label': 'Timeline Doubling Rate', 'value': 'confirmed_DR'},\n",
    "        {'label': 'Timeline Doubling Rate Filtered', 'value': 'confirmed_filtered_DR'},\n",
    "    ],\n",
    "    value='confirmed',multi=False),dcc.Graph(figure=fig, id='main_window_slope')])\n",
    "\n",
    "@app.callback(\n",
    "    Output('main_window_slope', 'figure'),\n",
    "    [Input('country_drop_down', 'value'),\n",
    "    Input('doubling_time', 'value')])\n",
    "def update_figure_layout(country_list,show_doubling):\n",
    "    if 'DR' in show_doubling:\n",
    "        my_yaxis={'type':\"log\",\n",
    "               'title':'Approximated doubling rate over 3 days (larger numbers are better #stayathome)'\n",
    "          }\n",
    "    else:\n",
    "        my_yaxis={'type':\"log\",\n",
    "                  'title':'Confirmed infected people (From johns hopkins csse, log-scale)'}\n",
    "    traces = []\n",
    "    for each in country_list:\n",
    "        df_plot=df_input_large[df_input_large['country']==each]\n",
    "\n",
    "        if show_doubling=='doubling_rate_filtered':\n",
    "            df_plot=df_plot[['state','country','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['country','date']).agg(np.mean).reset_index()\n",
    "        else:\n",
    "            df_plot=df_plot[['state','country','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['country','date']).agg(np.sum).reset_index()\n",
    "\n",
    "        traces.append(dict(x=df_plot.date,\n",
    "                                y=df_plot[show_doubling],\n",
    "                                mode='markers+lines',opacity=1.0,name=each))\n",
    "\n",
    "    return {\n",
    "            'data': traces,\n",
    "            'layout': dict (\n",
    "                width=1000,height=650,\n",
    "                xaxis={'title':'Timeline in the days','tickangle':-45,'nticks':20,\n",
    "                        'tickfont':dict(size=14,color=\"#0c6887\"),},yaxis=my_yaxis)}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.5 Calculation of SIR optimize parameter and fitted value\n",
    "* Here the calculation of optimized patameter beta, gamma and fitted value to plot simulated curve with original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load src/models/SIR_Calculation.py\n",
    "# importing required python packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from scipy import optimize\n",
    "from scipy import integrate\n",
    "\n",
    "#importing data frame\n",
    "data_raw = pd.read_csv('data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')\n",
    "country_list = data_raw['Country/Region'].unique() #making country_list\n",
    "date = data_raw.columns[4:]\n",
    "df_dhameli = pd.DataFrame({'Date': date})\n",
    "\n",
    "#converting data_raw DataFrame into format that we can use for SIR algorithm\n",
    "for each in country_list:\n",
    "    df_dhameli[each] = np.array(data_raw[data_raw['Country/Region'] == each].iloc[:,4::].sum(axis=0)).T\n",
    "df_dhameli.to_csv('data/processed/SIR.csv', sep = ';', index=False)\n",
    "\n",
    "df_analyse=pd.read_csv('data/processed/SIR.csv',sep=';')\n",
    "df_analyse.sort_values('Date',ascending=True).head()\n",
    "\n",
    "# Intialize parameter\n",
    "N0 = 1000000\n",
    "beta = 0.4\n",
    "gamma = 0.1\n",
    "I0=df_analyse.Germany[35]\n",
    "S0=N0-I0\n",
    "R0=0\n",
    "\n",
    "df_data = df_analyse[35:] # need to careful here because it difffers from each country!! But I solved it below\n",
    "t = np.arange(df_data.shape[0])\n",
    "\n",
    "# defining SIR function\n",
    "def cal_SIR_model_t(SIR, t, beta, gamma):\n",
    "    S,I,R=SIR\n",
    "    dS_dt = -beta*I*S/N0\n",
    "    dI_dt = beta*I*S/N0 - gamma*I\n",
    "    dR_dt = gamma*I\n",
    "    return dS_dt, dI_dt, dR_dt\n",
    "\n",
    "# defining fit_odeint_func function for optimize parameters\n",
    "def fit_odeint_func(x, beta, gamma):\n",
    "    return integrate.odeint(cal_SIR_model_t, (S0, I0, R0), x, args=(beta, gamma))[:,1]\n",
    "\n",
    "#calculating optimize parameters for every country\n",
    "for country in df_data.columns[1:]:\n",
    "        ydata = np.array(df_data[df_data[country]>0][country]) ## consider only value, which greater than zero to solve above mentioned problem\n",
    "        t = np.arange(len(ydata))\n",
    "        I0=ydata[0]\n",
    "        S0=N0-I0\n",
    "        R0=0\n",
    "        popt=[0.4,0.1]\n",
    "        fit_odeint_func(t, *popt)\n",
    "        popt, pcov = optimize.curve_fit(fit_odeint_func, t, ydata, maxfev=5000)\n",
    "        perr = np.sqrt(np.diag(pcov))\n",
    "        val_fitted=fit_odeint_func(t, *popt)\n",
    "        col_fitted = np.concatenate((np.zeros(df_data.shape[0]-len(val_fitted)) ,val_fitted)) # concatenate fitted and padded array into list\n",
    "        df_data[country + '_fitted'] = col_fitted\n",
    "\n",
    "df_data = df_data.reset_index(drop=True)\n",
    "#save CSV file to local drive for future use\n",
    "df_data.to_csv('data/processed/SIR_fitted.csv', sep = ';')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.6 Visual board_2\n",
    "* Visual board_2 shows real data and simulated SIR curve for one or multiple countries according selection of user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load src/visualization/Dashboard_2.py\n",
    "# importing required python packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "import plotly.graph_objects as go\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output,State\n",
    "print('Your current dash board version is:' + dash.__version__)\n",
    "\n",
    "#importing data frame\n",
    "df_analyse=pd.read_csv('data/processed/SIR_fitted.csv',sep=';')\n",
    "df_analyse.sort_values('Date',ascending=True).head()\n",
    "df_data = df_analyse.reset_index(drop = True)\n",
    "\n",
    "# for showing same color for each countries both curve, and color will be random at when you update the color list\n",
    "color_list = []\n",
    "for i in range(200):\n",
    "    var = '#%02x%02x%02x'%(random.randint(0,255),random.randint(0,255),random.randint(0,255))\n",
    "    color_list.append(var)\n",
    "\n",
    "# creating dashboard app containig plotting for whole dataset\n",
    "fig = go.Figure()\n",
    "app = dash.Dash()\n",
    "app.layout = html.Div([\n",
    "\n",
    "    dcc.Markdown('''\n",
    "\n",
    "    #  Data Science Project @ TU_KL on COVID-19 Dataset-Part 2\n",
    "    ## Real and simulated number of infected people\n",
    "\n",
    "    * The default layout contains the confirmed infected cases in the log-scale format on the Y-axis\n",
    "    and Timeline in Days on the X-axis.\n",
    "    ### The dropdown menu enables selection of one or multiple countries for visualization.\n",
    "\n",
    "    * This dashboard plots two curves for each country:\n",
    "\n",
    "    1. The first curve represents the confirmed infected cases along the timeline.\n",
    "    2. The second curve represents the simulated infected cases after applying the SIR model along the timeline.\n",
    "\n",
    "    '''),\n",
    "\n",
    "    dcc.Markdown('''\n",
    "    ## Multi-Select Country for visualization\n",
    "    '''),\n",
    "    dcc.Dropdown(\n",
    "        id='country_drop_down',\n",
    "        options=[ {'label': each,'value':each} for each in df_data.columns[1:200]],\n",
    "        value=['Germany','France'], # which are pre-selected\n",
    "        multi=True),dcc.Graph(figure=fig, id='main_window_slope')])\n",
    "\n",
    "@app.callback(\n",
    "    Output('main_window_slope', 'figure'),\n",
    "    [Input('country_drop_down', 'value')])\n",
    "def update_figure_layout(country_list):\n",
    "    v = 0\n",
    "    my_yaxis={'type':\"log\",'title':'Confirmed infected people (From johns hopkins csse, log-scale)'}\n",
    "    traces = []\n",
    "    for each in country_list:\n",
    "        traces.append(dict(x=df_data['Date'],y=df_data[each],\n",
    "                                mode='line', line = dict(color = color_list[v]), opacity=1.0,name=each))\n",
    "        traces.append(dict(x=df_data['Date'],\n",
    "                                y=df_data[each+'_fitted'],\n",
    "                                mode='markers+lines',line = dict(color=color_list[v]), opacity=1.0,name=each+'_simulated'))\n",
    "\n",
    "        v = v+1\n",
    "    return {\n",
    "            'data': traces,\n",
    "            'layout': dict (\n",
    "                width=1000,height=650,\n",
    "                xaxis={'title':'Timeline in Days','tickangle':-45,'nticks':20,\n",
    "                'tickfont':dict(size=14,color=\"#0c6887\"),},yaxis=my_yaxis)}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
