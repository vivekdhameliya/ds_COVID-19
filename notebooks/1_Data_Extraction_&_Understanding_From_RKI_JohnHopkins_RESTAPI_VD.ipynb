{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](CRISP_DM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required packages\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "# set limit for displaying max amount of raws values for dataframe\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set a base path in such way that full execuation will be possible with one click\n",
    "if os.path.split(os.getcwd())[-1]=='notebooks':\n",
    "    os.chdir('C:/Users/dhame/ds_covid-19/')\n",
    "\n",
    "'Your base path for this project is: '+os.path.split(os.getcwd())[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Data Extraction &Understanding\n",
    "* We have following three options available for extracting data....each explained in brief\n",
    "    * John Hopkins (GITHUB) https://github.com/CSSEGISandData/COVID-19.git\n",
    "    * RKI, webscrape (webscraping) https://www.rki.de/DE/Content/InfAZ/N/Neuartiges_Coronavirus/Fallzahlen.html\n",
    "    * REST API services to retreive data https://npgeo-corona-npgeo-de.hub.arcgis.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 JhonsHopkins GITHUB dataset\n",
    "* clonning data from Johnhopkins GITHUB page\n",
    "    * using command 'git clone/pull https://github.com/CSSEGISandData/COVID-19.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling data from github and storing in local drive\n",
    "git_pull = subprocess.Popen('git pull', \n",
    "                     cwd = os.path.dirname('data/raw/COVID-19/'), \n",
    "                     shell = True, \n",
    "                     stdout = subprocess.PIPE, \n",
    "                     stderr = subprocess.PIPE )\n",
    "(out, error) = git_pull.communicate()\n",
    "\n",
    "\n",
    "print(\"Error : \" + str(error)) \n",
    "print(\"out : \" + str(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='/data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "pd_raw=pd.read_csv(data_path)\n",
    "pd_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Webscrapping\n",
    "+ RKI, webscrape (webscraping) [Robert-koch website f√§lle](https://www.rki.de/DE/Content/InfAZ/N/Neuartiges_Coronavirus/Fallzahlen.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select page by giving URL of RKI Fallzahlen\n",
    "page = requests.get(\"https://www.rki.de/DE/Content/InfAZ/N/Neuartiges_Coronavirus/Fallzahlen.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_table = BeautifulSoup(page.content, 'html.parser')\n",
    "html_table=soup_table.find('table') # find the table, attention this works if one table exists\n",
    "all_rows=html_table.find_all('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_data_list=[]\n",
    "for pos,rows in enumerate(all_rows):\n",
    "    col_list=[each_col.get_text(strip=True) for each_col in rows.find_all('td')] #td for data element\n",
    "    absolute_data_list.append(col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_daily_status=pd.DataFrame(absolute_data_list).dropna().rename(columns={0:'state',\n",
    "                                                       1:'cases',\n",
    "                                                       2:'changes',\n",
    "                                                       3:'cases_per_100k',\n",
    "                                                       4:'fatal',\n",
    "                                                       5:'comment'})\n",
    "pd_daily_status.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 REST API \n",
    "* REST API services to retreive data [NPGEO website](https://npgeo-corona-npgeo-de.hub.arcgis.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating data request for Germany country\n",
    "data=requests.get('https://services7.arcgis.com/mOBPykOjAyBO2ZKk/arcgis/rest/services/Coronaf%C3%A4lle_in_den_Bundesl%C3%A4ndern/FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use json package to load data from called REST API\n",
    "json_object=json.loads(data.content) \n",
    "#checking data_type of Json_object\n",
    "type(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting keys of json file\n",
    "json_object.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty list name full_list and than append data from json_object\n",
    "full_list=[]\n",
    "for pos,each_dict in enumerate (json_object['features'][:]):\n",
    "    full_list.append(each_dict['attributes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert full_list to pandas dataframe\n",
    "pd_full_list=pd.DataFrame(full_list)\n",
    "pd_full_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe to local drive in CSV format\n",
    "pd_full_list.to_csv('C:/Users/dhame/ds_covid-19/data/raw/NPGEO/GER_state_data.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_full_list.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 Additional API Access via REST Dienst, i.e INDIA Dataset\n",
    "* example of REST confirm interface (Important!!!: Registration is required)\n",
    "* [Smartable](https://smartable.ai/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_endpoint = 'https://api.smartable.ai/coronavirus/stats/IN'\n",
    "headers = {\n",
    "    'Cache-Control': 'mo-cache',\n",
    "    'Subscription-Key': '22dc8d09733243328bacc2047f1c6f23'}\n",
    "response = requests.get(url_endpoint, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out what response content\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_dict = json.loads(response.content) # importing strings for India dataset and dump into JSON file with .txt format\n",
    "with open ('C:/Users/dhame/ds_covid-19/data/raw/IN_data.ext','w') as outfile:\n",
    "    json.dump(IN_dict, outfile,indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put all dictionary type data for INDIA into dataframe\n",
    "df_4 = pd.DataFrame(IN_dict)\n",
    "df_4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.4.1 Individual States India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_dict['stats']['breakdowns'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_list_IN_country=[]\n",
    "for pos,each_dict in enumerate (IN_dict['stats']['breakdowns'][:]):\n",
    "    flatten_dict=each_dict['location']\n",
    "    flatten_dict.update(dict(list(IN_dict['stats']['breakdowns'][pos].items())[1: 7]) \n",
    "    )\n",
    "    full_list_IN_country.append(flatten_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_india = pd.DataFrame(full_list_IN_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(full_list_IN_country).to_csv('C:/Users/dhame/ds_covid-19/data/raw/SMARTABLE/full_list_US_country.csv',sep=';',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
