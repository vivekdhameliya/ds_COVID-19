{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](CRISP_DM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from scipy import signal\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set a base path in such way that full execuation will be possible with one click\n",
    "if os.path.split(os.getcwd())[-1]=='notebooks':\n",
    "    os.chdir('C:/Users/dhame/ds_covid-19/')\n",
    "\n",
    "'Your base path for this project is: '+os.path.split(os.getcwd())[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Applying 'groupby' on large relational dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe creating using relational data frame of last notebook where all the data is sorted\n",
    "pd_JH_data=pd.read_csv('data/processed/COVID_relational_confirmed.csv',sep=';',parse_dates=[0])\n",
    "# start data value from ascending order and reset the index\n",
    "pd_JH_data=pd_JH_data.sort_values('date',ascending=True).reset_index(drop=True).copy()\n",
    "pd_JH_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Applying 'groupby' on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe with data of US and Germany after 20.03.2020\n",
    "test_data=pd_JH_data[((pd_JH_data['country']=='US')|\n",
    "                      (pd_JH_data['country']=='Germany'))&\n",
    "                     (pd_JH_data['date']>'2020-03-20')]\n",
    "test_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use groupby to check both countries max number of infected cases \n",
    "test_data.groupby(['country']).agg(np.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Doubling time via regression_ calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression(fit_intercept=True)\n",
    "#defining a function for calculating doubling time\n",
    "def get_doubling_time_via_regression(in_array):\n",
    "    ''' Use a linear regression to approximate the doubling rate'''\n",
    "\n",
    "    y = np.array(in_array)\n",
    "    X = np.arange(-1,2).reshape(-1, 1)\n",
    "\n",
    "    assert len(in_array)==3\n",
    "    reg.fit(X,y)\n",
    "    intercept=reg.intercept_\n",
    "    slope=reg.coef_\n",
    "    return intercept/slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Rolling regression\n",
    "#### # Thoery for understanding merge concept in python\n",
    "<font color=green> **Inner Merge / Inner join** – The default Pandas behaviour, only keep rows where the merge “on” value exists in both the left and right dataframes.  \n",
    "   **Left Merge / Left outer join** – (aka left merge or left join) Keep every row in the left dataframe. Where there are missing values of the “on” variable in the right dataframe, add empty / NaN values in the result.    \n",
    "   **Right Merge / Right outer join** – (aka right merge or right join) Keep every row in the right dataframe. Where there are missing values of the “on” variable in the left column, add empty / NaN values in the result.  \n",
    "   **Outer Merge / Full outer join** – A full outer join returns all the rows from the left dataframe, all the rows from the right dataframe, and matches up rows where possible, with NaNs elsewhere.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining function for calculation of rolling regression\n",
    "def rolling_regression(df_input,col='confirmed'):\n",
    "    ''' input has to be a data frame'''\n",
    "    ''' return is single series (mandatory for group by apply)'''\n",
    "    days_back=3\n",
    "    result=df_input[col].rolling(\n",
    "                window=days_back,\n",
    "                min_periods=days_back).apply(get_doubling_time_via_regression,raw=False)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby data using 'state' & 'country' columns and than apply rolling regerssion\n",
    "test_data[['state','country','confirmed']].groupby(['state','country']).apply(rolling_regression,'confirmed');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply rolling regression on our main dataframe and don't forget to reset index\n",
    "pd_DR_result=pd_JH_data[['state','country','confirmed']].groupby(['state','country']).apply(rolling_regression,'confirmed').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the column name for convenience\n",
    "pd_DR_result=pd_DR_result.rename(columns={'confirmed':'confirmed_DR','level_2':'index'})\n",
    "pd_JH_data=pd_JH_data.reset_index()\n",
    "pd_JH_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now merge the result of rolling regression with main data frame using common column named index column\n",
    "pd_result_larg=pd.merge(pd_JH_data,pd_DR_result[['index','confirmed_DR']],on=['index'],how='left')\n",
    "pd_result_larg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Applying Filter (savgol) on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define savgol_filter for filtering the data with groupby function\n",
    "def savgol_fil(df_input,column='confirmed',window=5):\n",
    "    ''' Savgol Filter which can be used in groupby apply function it ensures that the data structure is kept'''\n",
    "    window=5, \n",
    "    degree=1\n",
    "    df_result=df_input\n",
    "    # fillup empty raw with 0 value in dataframe\n",
    "    filter_in=df_input[column].fillna(0) \n",
    "    result=signal.savgol_filter(np.array(filter_in),\n",
    "                           5, # window size used for filtering\n",
    "                           1)\n",
    "    df_result[column+'_filtered']=result\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first apply groupby using state and country column data and than apply above function\n",
    "pd_filtered_result=pd_JH_data[['state','country','confirmed']].groupby(['state','country']).apply(savgol_fil).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge resulted value to large dataframe using common column name index\n",
    "pd_result_larg=pd.merge(pd_result_larg,pd_filtered_result[['index','confirmed_filtered']],on=['index'],how='left')\n",
    "pd_result_larg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Calculating doubling rate on filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering the doubling rate and save that into new dataframe\n",
    "pd_filtered_doubling=pd_result_larg[['state','country','confirmed_filtered']].groupby(['state','country'])\\\n",
    "                                .apply(rolling_regression,'confirmed_filtered').reset_index()\n",
    "pd_filtered_doubling=pd_filtered_doubling.rename(columns={'confirmed_filtered':'confirmed_filtered_DR','level_2':'index'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform mergeing as above using index as column and left \n",
    "pd_result_larg=pd.merge(pd_result_larg,pd_filtered_doubling[['index','confirmed_filtered_DR']],on=['index'],how='left')\n",
    "pd_result_larg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Masks in python\n",
    "<font color=green> # When working with data arrays masks can be extremely useful. Masks are an array of boolean values for which a condition is met.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mask=pd_result_larg['confirmed']>100\n",
    "pd_result_larg['confirmed_filtered_DR']=pd_result_larg['confirmed_filtered_DR'].where(df_maskask, other=np.NaN) \n",
    "#checking data for 'Germany' from the end\n",
    "pd_result_larg[pd_result_larg['country']=='Germany'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_result_larg.to_csv('data/processed/COVID_final_set.csv',sep=';',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
